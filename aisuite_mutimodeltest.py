# -*- coding: utf-8 -*-
"""AISuite_MutimodelTest

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16GShEG7RYKf48sXpSgJXKlvjs2UkcfsN
"""

!pip install 'aisuite[all]'

import os
from getpass import getpass
os.environ['OPENAI_API_KEY'] = getpass('Enter your OpenAI API key: ')
os.environ['ANTHROPIC_API_KEY'] = getpass('Enter your Anthropic API key: ')

import aisuite as ai
from pprint import pprint
import pandas as pd
client = ai.Client()

import aisuite as ai
import time
from pprint import pprint
from anthropic import RateLimitError

def ask(message, sys_message="You are a helpful agent.",
         model="groq:llama-3.2-3b-preview"):
    # Initialize the AI client for accessing the language model
    client = ai.Client()

    # Construct the messages list for the chat
    messages = [
        {"role": "system", "content": sys_message},
        {"role": "user", "content": message}
    ]

    # Send the messages to the model and get the response
    # Add retry logic for RateLimitError
    max_retries = 3  # Maximum number of retries
    retry_delay = 5  # Delay in seconds between retries
    for i in range(max_retries):
        try:
            response = client.chat.completions.create(model=model, messages=messages)
            return response.choices[0].message.content
        except RateLimitError:
            if i < max_retries - 1:  # Don't wait after the last retry
                print(f"Rate limit exceeded. Retrying in {retry_delay} seconds...")
                time.sleep(retry_delay)
            else:
                raise  # Re-raise the exception after max retries

input_csv_path = "/content/MultiLLMResponses - Sheet1.csv"
df = pd.read_csv(input_csv_path)

if 'Question' not in df.columns:
    raise ValueError("The CSV file must contain a 'question' column.")
df['OpenAI'] = ""
df['Anthropic'] = ""

for idx, row in df.iterrows():
    question = row['Question']
    print(f"Processing question {idx + 1}: {question}")

    # Get OpenAI response
    try:
        df.at[idx, 'OpenAI'] = ask(question, model="openai:gpt-4o")
    except Exception as e:
        print(f"Error with OpenAI model: {e}")
        df.at[idx, 'OpenAI'] = "Error"

    # Get Anthropic response
    try:
        df.at[idx, 'Anthropic'] = ask(question, model="anthropic:claude-3-5-sonnet-20240620")
    except Exception as e:
        print(f"Error with Anthropic model: {e}")
        df.at[idx, 'Anthropic'] = "Error"

output_csv_path = "/content/MultiLLMResponses_Processed.csv"
df.to_csv(output_csv_path, index=False)
print(f"Processed results saved to {output_csv_path}")

